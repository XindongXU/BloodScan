# 双模态YOLO模型：用于血液分层检测

这个项目实现了一个基于YOLO架构的双模态(白光/蓝光)图像分割模型，专门用于血液试管中血液分层的检测和分割。该模型同时利用白光和蓝光图像的互补信息，通过变形注意力机制(Deformable Attention)和交叉变换器(Cross Transformer)实现特征融合，提高对血液分层的检测精度。

## 模型特点

- **双backbone架构**：分别处理白光和蓝光两种模态的输入图像
- **跨模态特征融合**：利用变形注意力机制和跨模态Transformer实现特征对齐和融合
- **多尺度特征交互**：在backbone的多个层次上进行模态间的特征交互
- **共享检测头**：融合后的特征共享同一个YOLO检测/分割头

## 模型架构

```
                    ┌─────────────────┐
                    │  白光图像输入    │
                    └────────┬────────┘
                             │
                    ┌────────▼────────┐    ┌─────────────────┐
                    │  白光Backbone    │    │  蓝光图像输入    │
                    └────────┬────────┘    └────────┬────────┘
                             │                      │
                             │             ┌────────▼────────┐
          ┌─────┬─────┬──────┘             │   蓝光Backbone   │
          │     │     │                    └────────┬────────┘
┌─────────▼─┐ ┌─▼───┐ ┌▼────┐                      │
│P3特征(白光)│ │P4特征│ │P5特征│                      │
└─────────┬─┘ └─┬───┘ └┬────┘            ┌─────┬─────┬──────┘
          │     │     │                  │     │     │
          │     │     │          ┌───────▼───┐ ┌─▼───┐ ┌▼────┐
 ┌────────▼─────▼─────▼─────┐    │P3特征(蓝光)│ │P4特征│ │P5特征│
 │ Cross Transformer融合模块 │    └───────┬───┘ └─┬───┘ └┬────┘
 └────────┬──────┬────┬─────┘            │       │      │
          │      │    │                  │       │      │
   ┌──────▼──┐ ┌─▼──┐ ┌▼───┐             │       │      │
   │P3融合特征│ │P4特征│ │P5特征│◄───────────┘       │      │
   └─────────┘ └────┘ └────┘◄─────────────────────┘      │
          │      │      │◄─────────────────────────────────┘
          │      │      │
   ┌──────▼──────▼──────▼────┐
   │         YOLO Neck        │
   └────────────┬─────────────┘
                │
   ┌────────────▼─────────────┐
   │     YOLO 检测/分割头      │
   └────────────┬─────────────┘
                │
   ┌────────────▼─────────────┐
   │         预测结果          │
   └──────────────────────────┘
```

## 跨模态Transformer实现

模型的核心是跨模态特征融合模块，它包含以下关键组件：

1. **变形偏移预测**：学习从一个模态到另一个模态的空间对应关系
2. **空间变换层**：根据预测的偏移量对特征进行变形，实现空间对齐
3. **跨模态注意力**：对齐后的特征通过注意力机制交换信息
4. **特征融合**：将增强后的特征组合为单一表示，作为后续检测的输入

## 文件结构

- `model.py` - 模型架构定义，包含DualModalYOLO模型和CrossTransformer实现
- `dataset.py` - 双模态数据加载和预处理
- `train.py` - 模型训练脚本
- `predict.py` - 预测和推理脚本
- `utils.py` - 辅助函数和工具
- `config.py` - 配置参数

## 环境需求

- Python 3.8+
- PyTorch 1.10+
- Ultralytics (YOLO v8)
- OpenCV
- Albumentations

详细依赖可在requirements.txt中查看。

## 使用方法

### 数据准备

将白光和蓝光图像分别放在对应的目录中，标注文件采用YOLO格式。确保白光和蓝光图像可以通过文件名进行匹配。

```
data/
  └── blood_samples/
      ├── train/
      │   ├── white/  # 白光训练图像
      │   ├── blue/   # 蓝光训练图像
      │   └── labels/ # 训练标签
      ├── val/
      │   ├── white/  # 白光验证图像
      │   ├── blue/   # 蓝光验证图像
      │   └── labels/ # 验证标签
      └── test/
          ├── white/  # 白光测试图像
          └── blue/   # 蓝光测试图像
```

### 训练模型

```bash
python train.py --config configs/blood_sample_config.yaml
```

### 预测

```bash
python predict.py --white-img path/to/white_image.jpg --blue-img path/to/blue_image.jpg --weights path/to/weights.pt
```

## 引用

如果您在研究中使用了本项目，请引用：

```
@misc{dual-modal-yolo,
  author = {Your Name},
  title = {Dual Modal YOLO for Blood Layer Segmentation},
  year = {2023},
  publisher = {GitHub},
  howpublished = {\url{https://github.com/yourusername/dual-modal-yolo}}
}
```

## 许可证

MIT

## 致谢

- 本项目基于[Ultralytics YOLO](https://github.com/ultralytics/ultralytics)
- 变形注意力机制参考了[MICFormer](https://arxiv.org/abs/2404.16371)的实现 