- 文献综述与相关文献整理
1. yolov8 to yolo11-综述
该文献系统梳理了YOLOv8至YOLO11的架构演进，重点比较各版本在结构设计、特征提取、效率与检测性能等方面的改进。方法上，作者通过深入分析官方文档、学术论文和源代码，重建了各版本的详细结构图，并对关键模块（如C2f、C3k2、SPPF、C2PSA、PSA等）进行了功能与效率对比。结论指出，YOLO系列持续引入注意力机制、空间金字塔池化、轻量化卷积和高效特征融合，逐步提升了多尺度目标检测能力和推理速度。然而，文献也强调，部分新版本缺乏正式学术发表和结构图，给后续研究和实际应用带来障碍。
与本课题算法的具体比较  
- 多模态特征提取与融合策略
文献方法依赖单一图像模态，特征提取与融合均在单通道RGB空间进行；而你的算法采用双backbone架构，分别针对白光和蓝光图像提取多尺度特征，并设计了变形跨模态Transformer实现深层信息对齐与融合，大幅拓展了特征表达能力。
- 该文献仅聚焦单模态自然图像，未涉及多模态或医学影像场景，缺乏对跨模态特征融合、空间配准等难题的探讨。  
- YOLO各版本的结构创新多聚焦于通用场景，未针对医学影像中常见的低对比度、模态差异、空间失配等具体难题提出系统解决方案。  
- 文献未对YOLO在医学图像（如血液分层检测）中的适用性和局限性进行实验或理论分析。

2.transmed-分类
Classification》聚焦于提升多模态医学图像分类性能，针对MRI等多模态输入，提出了结合CNN与Transformer的TransMed架构。该方法利用CNN高效提取局部低层次特征，再借助Transformer建模跨模态、跨切片的长距离依赖，实现了多模态特征的深度融合。文献系统比较了输入级、特征级、决策级三种传统融合策略，指出各自存在信息交互不足、计算量大或无法建模模态间显式关系等问题。TransMed通过序列化多模态图像、CNN编码、Transformer全局交互的混合范式，显著提升了腮腺肿瘤分类的准确率和效率，实验结果优于主流3D CNN及多分支融合网络。
其创新点主要体现在：（1）首次将Transformer引入多模态医学图像分类，利用自注意机制显式建模模态间及空间切片间的关系；（2）提出CNN-Transformer混合架构，有效缓解纯Transformer在小样本医学数据上的泛化不足；（3）提出高效的多模态序列化与融合方法，兼顾局部与全局依赖。关键技术路线为：序列化输入→CNN提特征→Transformer跨模态建模→分类输出。
局限性方面，TransMed主要存在：（1）对空间不对齐等实际多模态配准问题考虑不足，仅通过注册和简要预处理，未设计专门的空间对齐机制；（2）方法主要面向分类任务，未针对检测、分割等结构化输出场景优化；（3）虽然Transformer提升了全局特征交互，但对于细粒度空间变形、局部边界等问题处理能力有限；（4）对模态间噪声、光学差异的鲁棒性未深入探讨。

3.PHantom yolo+简化+单通道+多模态同时输入-检测任务
聚焦于资源受限场景下的多模态目标检测问题，尤其针对低照度和遮挡环境。作者提出了YOLO Phantom模型，通过引入Phantom Convolution模块，极大压缩模型参数量，实现了在保持准确率的同时提升推理速度。其多模态检测能力体现在RGB与红外（热成像）图像的融合上，并通过在FLIRV2数据集上训练与评测，验证了模型在低光照条件下的有效性。该方法适合IoT边缘设备，并集成了完整的检测-通知系统，展示了实际应用潜力。
主要创新点在于：1）设计极致轻量化的YOLO结构，采用Phantom Convolution（结合Depthwise Separable与Group Convolution）显著降低计算资源消耗；2）支持多模态（RGB/红外）输入，通过转移学习提升对低光和遮挡场景的鲁棒性；3）提出端到端的IoT集成应用，完成从采集、检测到云端通知的全流程。
该方法也存在局限：首先，多模态融合仅限于简单的输入级或特征级拼接，未针对模态间空间不对齐等复杂问题设计专门的对齐机制。其次，特征交互主要依赖轻量化卷积操作，缺乏像Transformer等强表达力机制，对跨模态深层信息融合能力有限。

4. MAF-YOLO

5.JANUS-产品
该报告介绍了PerkinElmer公司推出的JANUS Blood iQ工作站，这是一套针对血液分层与cfDNA/cfRNA/gDNA提取的全自动化解决方案。其核心在于通过深度学习驱动的图像分析方法，结合自动化精密移液与机器人操作，实现了血液分层（血浆、buffy coat等）的高效、可追溯和重现性处理。图像处理方面，工作站利用蓝光和白光成像技术分别识别血细胞层与血浆层的位置，通过深度学习模型自动分割层界，并据此指导后续的液体转移和下游核酸分析。该系统特别适用于生物样本库和大规模基因分析前的样本预处理流程。
局限性与不足  
尽管该系统在自动化血液分层中表现出较高的精度，但其深度学习模型主要服务于传统的图像分割和层界识别方法，也未对多模态特征进行深层语义对齐与融合处理。文献未详细披露模型结构和对模态间空间不对齐问题的具体解决方案。此外，系统主要依赖于固定的成像与预设流程，对于复杂或异常样本的适应性有限，缺乏灵活的特征交互和自适应增强机制。
JANUS系统利用蓝光和白光图像，但其特征融合主要体现在决策层，即通过独立成像后分别提取层高信息，并未在深层特征空间实现模态互补。相比之下，您的双模态YOLO算法采用双backbone结构，在特征提取早期即对多模态信息进行深度耦合，并设计了多种融合策略（加权、拼接、Transformer），实现更细粒度的信息交互与增强。
文献方法对空间不对齐问题处理较为粗略，主要依赖几何参数和模型推断层界高度。您的方法创新性地引入内容感知空间对齐机制，通过变形跨模态Transformer和像素级偏移场预测，显著提升了模态间空间一致性和细节对齐能力。  
JANUS® G3侧重于单一模态独立分析，缺乏跨模态特征交互设计。您的算法通过跨模态多头注意力机制，在多个语义层次（如YOLO的P3/8、P4/16、P5/32特征层）实现双向增强，兼顾局部细节和全局语义，提升了模型对复杂血液分层边界的感知力。

7.CT-MRI multimodal image segmentation-整体语义分割
该文献针对医学多模态图像分割任务，提出了MicFormer架构，旨在高效融合CT与MRI等多源医学图像信息，以提升分割精度。核心关注点在于如何实现多模态特征的有效对齐与交互，克服传统融合方法易引入冗余或无关信息的问题。文中采用并行双流结构分别提取各模态特征，通过变形跨模态Transformer（Deformable Cross-attention）实现跨模态特征对齐与信息交互，并在心脏分割任务上取得了优异的DICE与MIoU指标。
MicFormer的主要创新包括：  
（1）双流U-Net结构，分别抽取每种模态的多层次特征，避免早期无约束的信息混杂；  
（2）引入变形跨模态Transformer模块，通过可学习的局部空间偏移，实现跨模态特征的动态对齐和互补信息增强，有效缓解传统Transformer在固定窗口下对位移敏感的问题；  
（3）连续的特征交互机制，通过多层级递归的cross-attention，促进模态间深层信息融合。该方法在MM-WHS数据集上显著提升了分割性能，优于SOTA方法。
局限性与不足  
MicFormer虽在分割精度上表现突出，但存在如下不足：（1）方法复杂度高，需训练双流网络与多层Transformer，计算资源消耗大；（2）偏重结构分割，对细粒度目标（如微小血液分层）或空间动态变化的适应性有限；（3）空间对齐核心依赖于局部窗口内变形，对大范围或高度非线性空间错配的场景可能能力不足；（4）主要针对医学分割，未针对检测与实例分层等任务进行优化。
与本课题的比较  
a) 多模态特征提取与融合：MicFormer采用并行Swin-Unet结构叠加跨模态Transformer，适用于语义分割；而你的方法则基于双backbone设计，结合YOLO检测框架，针对目标检测和实例分层特征，强调多尺度特征自适应融合，并提出加权/拼接/Transformer多策略融合机制，融合策略更为灵活多样。

8.血清质量评估-分类
旨在利用深度学习方法实现血清样本质量的自动评估，重点解决传统人工视觉判读主观性强、效率低以及传统图像分割算法抗干扰能力差等问题。作者基于单一白光图像，采用Inception-Resnet-V2网络对血清样本图像进行分类与回归，能够自动判别溶血、黄疸及乳糜等多种干扰，并预测相关生化指标（如HIL-indices和总胆红素）。实验结果表明，该方法在多分类任务上AUC均超过0.98，显著优于传统基于RGB分割的算法。
（1）首次大规模采集临床血清样本图像，建立了带有真实生化指标标签的高质量数据集；（2）将深度卷积神经网络应用于血清质量自动判读，实现多类别分类与生化指标回归的端到端预测；（3）系统集成于实际实验室流程中，具备一定的落地应用价值。该方法有效提高了判读准确率，降低了不必要的实验检测。
然而，该文献方法存在如下不足：（1）仅使用单一模态（白光）图像，未考虑其他光谱成像的互补信息，可能对部分边界模糊、结构复杂或光照干扰强的样本存在识别瓶颈；（2）对图像中空间不对齐或样本位置变化的处理较为有限，主要依赖于卷积神经网络的空间容忍性，缺乏显式的对齐机制；（3）特征融合仅限于单通道内部，未设计多模态或多源信息的深度交互结构，影响对复杂干扰的鲁棒性。


10.飞机玻璃划痕检测-OBB检测
主要聚焦于透明材料缺陷检测中单一光照条件的局限性，提出了基于正向与背向照明的双模态成像系统及相应的多模态融合方法。该文献的核心贡献包括：1）设计并搭建了双模态照明成像平台，首次实现同一位置下正向与背向照明图像的同步采集；2）建立了针对航空玻璃的缺陷检测数据集，采用旋转包围框（OBB）标注多类缺陷；3）提出了两种融合策略——数据级的RGB通道融合与特征级的注意力双分支融合网络（ADMF-Net）
1）空间对齐未作为重点问题处理，正、背光图像通过硬件保证空间配准，但对光学变形、局部非刚性错位等实际工业场景下更为复杂的空间不一致问题未作深入建模；2）特征融合策略较为常规，主要依赖通道与空间注意力，缺少针对跨模态空间对齐与细粒度特征互补的机制；

11.待研究Medical Physics - 2023 - Liu - A modality‐collaborative convolution and transformer hybrid network for unpaired multi‐modal-整体语义分割

12.RGB-D multi-modal feature fusion
该文献以复杂户外环境下高精度茶芽检测为目标，提出了一种基于YOLOv7的RGB-D多模态融合检测网络（YOLO-RGBDtea）。其核心是利用RGB图像的纹理与色彩信息结合深度图像的空间结构优势，提升小目标、重叠目标与极端光照下的检测能力。方法上，文献设计了双backbone结构分别提取RGB与深度特征，引入轻量化depth-backbone和自注意力机制（BoT），并通过提出的单向跨模态空间注意力融合模块（CSFM）实现特征融合。
局限性与不足  
- 特征融合方式为单向补充，未实现双向或深度特征对RGB特征的充分反哺，信息利用可能不充分。
- 融合策略偏向简单空间权重调节，未涉及复杂的空间对齐、变形或像素级校正，难以处理大尺度空间不对齐。

13.待研究-Multi-modal semantic image segmentation

14.Bright Channel Prior Attention for Multispectral Pedestrian Detection
聚焦于低光照环境下多光谱行人检测任务，提出了融合可见光和红外热成像的YOLOv4改进模型。其核心贡献包括：1）利用热成像HSV空间的V通道（亮度）作为注意力引导，激发对可见光图像的无监督特征增强，使检测网络关注于行人区域；2）引入基于Bright Channel Prior（BCP）的低光增强模块，通过无监督损失优化照明图，实现夜间图像的亮度补偿；3）将图像增强与目标检测统一于同一框架内，提升低照环境下的检测性能。实验在LLVIP数据集上表明，该方法在准确率、召回率和mAP等指标上均优于普通YOLOv4及其多通道变体。
文献的主要创新在于跨模态注意力机制（热成像亮度引导可见光特征学习）以及BCP无监督低光增强算法的集成，针对低光环境下可见光信息缺失、单一模态局限性及行人目标难以分割等问题，实现了信息互补与增强。然而，文献方法也存在一定局限性：（1）多模态融合主要依赖注意力引导而非结构性特征对齐，难以应对复杂空间不对齐或视差大场景；（2）关注于一般目标检测任务，缺乏对细粒度结构与医学图像等特殊场景的适配；（3）特征融合方式较为简单，未充分利用Transformer等先进跨模态交互机制，且在多尺度语义与空间细节整合方面手段有限。
与您的双模态YOLO算法相比，二者在多模态特征提取与融合策略上均采用了双分支结构，但文献方法侧重于利用热成像对可见光分支进行注意力引导，而您的方法引入了变形跨模态Transformer，通过空间变形网络实现像素级对齐，显著增强了在光学畸变和模态空间不一致场景下的鲁棒性。在特征交互与增强机制方面，文献仅采用注意力和简单拼接，而您的方法结合了多头注意力与空间重采样，实现了更深层次的信息交互和上下文增强，特别适合血液分层等结构复杂、边界细节要求高的医学图像分析任务。此外，您的方法在融合策略（加权、拼接、Transformer）和多尺度（P3、P4、P5）双向增强方面更为灵活和全面，能有效兼顾局部细节与全局语义，提升分层检测的精度与鲁棒性。