## **视觉算法整体方案（YOLO Dual-Backbone + 三种特征融合）**

### 1. 双骨干输入流（Blue-White Dual Backbone）

1. **输入**

   * 同一拍摄坐标系下获取的蓝光图 $I_b$ 与白光图 $I_w$。
   * 预处理：统一分辨率、归一化、按 batch 组对齐。

2. **Backbone 设计**

   * 为两幅图各配置一条 *YOLO-11* 轻量主干（CSPDark-11 变体），参数独立但结构对称：

     $$
       I_b \xrightarrow{\text{Backbone}_b} \{F_b^{C2},F_b^{C3},F_b^{C4},F_b^{C5}\},\qquad
       I_w \xrightarrow{\text{Backbone}_w} \{F_w^{C2},F_w^{C3},F_w^{C4},F_w^{C5}\}.
     $$
   * 每级特征保持 $C$ 个通道（例如 $C{=}256$）与对应空间尺寸 $H_s\times W_s$。

3. **多尺度路径**

   * 采用 YOLO 的 **FPN + PAN** 颈部将各级特征自底向顶、再自顶向底传递，途中插入“融合块”实现两模态互补。
   * “融合块”对 $\bigl(F_b^{Cs},F_w^{Cs}\bigr)$ 分别在 $s\in\{C2,C3,C4,C5\}$ 上运行，输出融合后的 $F_{\!*}^{Cs}$ 送往下一步金字塔堆叠。

---

### 2. 三种融合策略

#### 2.1 加权求和（Add）

* **权重预测**

  $$
    \alpha_s = \sigma\!\bigl(\text{FC}(\text{GAP}([F_b^{Cs};F_w^{Cs}]))\bigr),\qquad
    \alpha_s\in[0,1]^{C}.
  $$

  其中 GAP 为全局平均池化，$\sigma$ 为 Sigmoid。若按像素预测，可保留空间维度。

* **融合公式**

  $$
    F_{\text{add}}^{Cs}= \alpha_s\!\odot\!F_b^{Cs} \;+\; \bigl(1-\alpha_s\bigr)\!\odot\!F_w^{Cs}.
  $$

* **特点**：参数量极小，对比度敏感区域自动调节蓝/白信息占比，端到端学习。

---

#### 2.2 通道拼接（Concat + 1 × 1 Conv）

1. **拼接**

   $$
     F_{\text{raw}}^{Cs}= [F_b^{Cs};F_w^{Cs}]\in\mathbb R^{2C\times H_s\times W_s}.
   $$

2. **线性压缩**

   $$
     F_{\text{cat}}^{Cs}= W_c^{Cs} * F_{\text{raw}}^{Cs},\qquad
     W_c^{Cs}\in\mathbb R^{C\times2C\times1\times1}.
   $$

3. **特点**：保留两路全部通道信息，再用 $1\times1$ 卷积进行跨模态静态混合；计算友好、易用作基线。

---

#### 2.3 双向 Cross Transformer（Bidirectional X-Attn）

1. **线性映射**

   $$
     Q_b=F_b^{Cs}W_q,\; K_b=F_b^{Cs}W_k,\; V_b=F_b^{Cs}W_v,\\
     Q_w=F_w^{Cs}W_q,\; K_w=F_w^{Cs}W_k,\; V_w=F_w^{Cs}W_v.
   $$

2. **双向跨注意力** （单式写法将权重与汇聚合并）

   $$
     \begin{aligned}
       F_{b\leftarrow w}^{Cs} &= \operatorname{Softmax}\!\bigl(Q_bK_w^{\!\top}/\sqrt{d}\bigr)\,V_w,\\[4pt]
       F_{w\leftarrow b}^{Cs} &= \operatorname{Softmax}\!\bigl(Q_wK_b^{\!\top}/\sqrt{d}\bigr)\,V_b.
     \end{aligned}
   $$

3. **残差回写 + 映射**

   $$
     F_{\text{ctr}}^{Cs} = \phi\!\bigl(F_b^{Cs}+F_{b\leftarrow w}^{Cs}\bigr) \;+\; 
                            \phi\!\bigl(F_w^{Cs}+F_{w\leftarrow b}^{Cs}\bigr),
   $$

   其中 $\phi$ 由 $1\times1$ Conv + LayerNorm 组成。由于两幅图几何对齐，无需形变对齐模块。

4. **特点**：显式学习“蓝光加强白光 / 白光反哺蓝光”的细粒度对应关系，在液层边界、高反光等复杂区域提供更强判别表示，代价适中，能与 YOLO 检测头端到端训练。

---

### 3. 输出及检测头

* 将融合后的 $\{F_{\!*}^{C2},F_{\!*}^{C3},F_{\!*}^{C4},F_{\!*}^{C5}\}$ 继续通过 PAN 路径上采 / 下采，形成最终 $\{P3,P4,P5\}$ 三尺度特征。
* **YOLO-Head** 延用 anchor-free 解耦头（Cls / Reg / Obj），直接在多光谱增强特征上预测边界框与类别。
* Loss 采用 CIoU + BCE + 偏重难样本的 Focal Loss，整体训练策略与单模态 YOLO 一致，仅需额外学习融合模块参数。

---

### 4. 小结

* **双骨干** 保证各模态独立抽象能力；
* **Add / Concat / X-Attn** 三路可插拔融合，为实验提供由浅入深的对照；
* **数学闭合** 的轻量公式确保实现可复现、梯度可传播；
* 整体网络保持 YOLO 框架的实时性，同时显著提升双色成像场景下对液面、血层等细节的检测与分割精度。
